{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How wavelet packet energy features were calculated\n",
    "\n",
    "While applying (shallow) machine learning algorithms for condition monitoring task, we first calculate features from raw time domain data and then apply the algorithms to the feature matrix. In our code demonstrations we have extensively used wavelet packet energy as well as wavelet packet entropy features. In this notebook, we will show how to calculate wavelet packet energy features. Wavelet packet energy and wavelet packet entropy features can be calculated in Python and R. But we will use MATLAB to calculate it. We do so, because our aim is to reproduce the same feature matrix that we have used in all our algorithms from raw time domain data. In Python and R, equivalent commands are not available (to the best of my knowledge) that can reprodce the feature matrix that we use in our experiments.\n",
    "\n",
    "**Update**: See [this notebook](https://github.com/biswajitsahoo1111/cbm_codes_open/blob/master/notebooks/Wavelet_packet_energy_features_python.ipynb) to compute wavelet packet energy features entirely in Python. As we have mentioned above, the feature matrix obtained using Python will not be exactly equal to the feature matrix that we have used in our analysis. But it will be close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the time domain data from [here](https://github.com/biswajitsahoo1111/cbm_codes_open/blob/master/notebooks/data/CWRU_48k_load_1_CNN_data.npz) and run the following cells. See [this notebook](https://github.com/biswajitsahoo1111/cbm_codes_open/blob/master/notebooks/CWRU_time_domain_data_preprocessing.ipynb) to understand how the time domain data was prepared at the first place. This data will be used later in [deep learning demonstration](https://github.com/biswajitsahoo1111/cbm_codes_open/blob/master/notebooks/Deep_Learning_CWRU_Blog.ipynb). We use the same time domain data and calculate features from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'labels']\n"
     ]
    }
   ],
   "source": [
    "file = np.load(\"./data/CWRU_48k_load_1_CNN_data.npz\")\n",
    "print(file.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4600, 32, 32) (4600,)\n"
     ]
    }
   ],
   "source": [
    "data = file['data']\n",
    "labels = file['labels']\n",
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the raw signal into segments of length 1024 each. For each fault type we collect 460 segments. There are 10 fault types, so we get 4600 segments in total. As the data were prepared for a CNN task, we further resize the data into a size of $(32 \\times 32)$. So final size of data becomes $(4600 \\times 32 \\times 32)$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ball_007', 'Ball_014', 'Ball_021', 'IR_007', 'IR_014', 'IR_021',\n",
       "       'Normal', 'OR_007', 'OR_014', 'OR_021'], dtype='<U8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2300, 2048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_data = np.reshape(data, (2300,2048))\n",
    "resized_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We resize the data this way because for shallow leraning applications we consider segments of length 2048 and calculate features using the data of this segment. There is no particular reason in choosing segments of length 2048 as opposed to 1024 or 4096 or any othre number. One consideration might be the amount of raw data available. If we select a larger segment length, we will get less number of segments. And if we need more segments (this is a need in machine learning), we keep the segment length short. However, keep in mind that reducing the segment length to an arbitrarily small number might not be that useful as small segments might not capture useful events that are characteristic of bearing faults. It so happens that the author chose a segment length of 2048 for this dataset and the resulting feature matrix yielded excellent results. Thus, the author has not changed the segment length ever since."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save the data in npy file and load it in matlab. [Refer to this page](https://github.com/kwikteam/npy-matlab) that explains the procedure to read npy files into MATLAB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cwru_resized\", resized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below is in MATLAB. Don't run it in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is matlab code\n",
    "\n",
    "# data = readNPY('cwru_resized.npy');\n",
    "# matrix = NaN(2300,8);\n",
    "# for i = 1:size(data,1)\n",
    "#     [~,~,~,energy] = modwpt(data(i,:),'sym8',3); % Read matlab documentation to figure out what this line does\n",
    "#     matrix(i,:) = energy;\n",
    "# end\n",
    "# csvwrite(\"check_cwru_energy.csv\",matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you have MATLAB installed in your system, you can run the commands in the above cell in MATLAB and compare the saved csv file `check_cwru_energy.csv` with [feature_wav_energy8_48k_2048_load_1.csv](https://github.com/biswajitsahoo1111/cbm_codes_open/blob/master/notebooks/data/feature_wav_energy8_48k_2048_load_1.csv) that is available at the author's github page. You will observe that data in both the files are identical. If you don't have MATLAB installed in you system, you have to accept my word that data in both the files are indeed identical. Similarly, other features matrices can now be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
