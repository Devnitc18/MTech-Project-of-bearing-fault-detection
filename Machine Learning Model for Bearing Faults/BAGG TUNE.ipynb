{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5cf906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.9, 'n_estimators': 15}\n",
      "Overall training accuracy: 0.890625\n",
      "Overall test accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_time_48k_2048_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=700, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd3f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.9, 'n_estimators': 15}\n",
      "Overall training accuracy: 0.8564814814814815\n",
      "Overall test accuracy: 0.8433333333333334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_time_12k_1024_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=300, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e520c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.9, 'n_estimators': 10}\n",
      "Overall training accuracy: 0.77\n",
      "Overall test accuracy: 0.7771428571428571\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_wav_energy8_48k_2048_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=700, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66c2afc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.9, 'n_estimators': 15}\n",
      "Overall training accuracy: 0.7083333333333334\n",
      "Overall test accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_wav_energy8_12k_1024_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=300, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c607d6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.9, 'n_estimators': 10}\n",
      "Overall training accuracy: 0.858125\n",
      "Overall test accuracy: 0.8757142857142857\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_wav_ent8_shan_48k_2048_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=700, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07d6659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.9, 'n_estimators': 10}\n",
      "Overall training accuracy: 0.8416666666666667\n",
      "Overall test accuracy: 0.8366666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_wav_ent8_shan_12k_1024_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=300, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e283c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.9, 'n_estimators': 10}\n",
      "Overall training accuracy: 0.89375\n",
      "Overall test accuracy: 0.8842857142857142\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_time_48k_2048_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=700, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = SVC(probability=True)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa1684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.7, 'n_estimators': 15}\n",
      "Overall training accuracy: 0.9027777777777778\n",
      "Overall test accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_time_12k_1024_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=300, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = SVC(probability=True)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "922a8d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.9, 'n_estimators': 15}\n",
      "Overall training accuracy: 0.835625\n",
      "Overall test accuracy: 0.8442857142857143\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_wav_energy8_48k_2048_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=700, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = SVC(probability=True)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e358ab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.9, 'n_estimators': 15}\n",
      "Overall training accuracy: 0.9342592592592592\n",
      "Overall test accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_wav_energy8_12k_1024_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=300, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = SVC(probability=True)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f0e379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.9, 'n_estimators': 15}\n",
      "Overall training accuracy: 0.888125\n",
      "Overall test accuracy: 0.8971428571428571\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_wav_ent8_shan_48k_2048_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=700, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = SVC(probability=True)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb9a587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.7, 'n_estimators': 15}\n",
      "Overall training accuracy: 0.9518518518518518\n",
      "Overall test accuracy: 0.9633333333333334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "data_wav_energy = pd.read_csv(\"data_feature_wav_ent8_shan_12k_1024_load_1.csv\")\n",
    "data_wav_energy['fault'] = pd.Categorical(data_wav_energy['fault'])\n",
    "\n",
    "# Remove collinear features\n",
    "corr_matrix = data_wav_energy.iloc[:, :-1].corr().abs()\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape, dtype=bool), k=1))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9)]\n",
    "data_wav_energy.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "train_wav_energy, test_wav_energy = train_test_split(data_wav_energy, test_size=300, stratify=data_wav_energy['fault'], random_state=324)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_wav_energy_scaled = scaler.fit_transform(train_wav_energy.iloc[:, :-1])\n",
    "test_wav_energy_scaled = (test_wav_energy.iloc[:, :-1].values - scaler.mean_) / np.sqrt(scaler.var_)\n",
    "\n",
    "base_classifier = SVC(probability=True)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [5, 10, 15],\n",
    "    'max_samples': [0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = BaggingClassifier(base_estimator=base_classifier)\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5)\n",
    "grid_search.fit(train_wav_energy_scaled, train_wav_energy['fault'])\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "train_predictions = best_bagging_clf.predict(train_wav_energy_scaled)\n",
    "test_predictions = best_bagging_clf.predict(test_wav_energy_scaled)\n",
    "\n",
    "train_confu_matrix = confusion_matrix(train_wav_energy['fault'], train_predictions)\n",
    "test_confu_matrix = confusion_matrix(test_wav_energy['fault'], test_predictions)\n",
    "\n",
    "train_accuracy = accuracy_score(train_wav_energy['fault'], train_predictions)\n",
    "print(\"Overall training accuracy:\", train_accuracy)\n",
    "\n",
    "test_accuracy = accuracy_score(test_wav_energy['fault'], test_predictions)\n",
    "print(\"Overall test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20cb72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
